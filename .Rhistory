o = order(df[, 2], df[, 1])
df[o, ][num, 1]
}
rankhospital("MN", "heart attack", 5000)
rankhospital("MN", "heart attack", 5000)
rankhospital("MN", "heart attack", 5000)
rankhospital("TX", "heart failure", 4)
rankhospital("MN", "heart attack", 5000)
rankhospital("MD", "heart attack", "worst")
rankall <- function(outcome, num = "best") {
## Read the outcome data
dat <- read.csv("outcome-of-care-measures.csv", colClasses = "character")
## Check that state and outcome are valid
states = unique(dat[, 7])
switch(outcome, `heart attack` = {
col = 11
}, `heart failure` = {
col = 17
}, pneumonia = {
col = 23
}, stop("invalid outcome"))
## Return hospital name in that state with the given rank 30-day death rate
dat[, col] = as.numeric(dat[, col])
dat = dat[, c(2, 7, col)]  # leave only name, state, and death rate
dat = na.omit(dat)
# head(dat) Hospital.Name State 1 SOUTHEAST ALABAMA MEDICAL CENTER AL 2
# MARSHALL MEDICAL CENTER SOUTH AL 3 ELIZA COFFEE MEMORIAL HOSPITAL AL 7 ST
# VINCENT'S EAST AL 8 DEKALB REGIONAL MEDICAL CENTER AL 9 SHELBY BAPTIST
# MEDICAL CENTER AL
# Hospital.30.Day.Death..Mortality..Rates.from.Heart.Attack 1 14.3 2 18.5 3
# 18.1 7 17.7 8 18.0 9 15.9
rank_in_state <- function(state) {
df = dat[dat[, 2] == state, ]
nhospital = nrow(df)
switch(num, best = {
num = 1
}, worst = {
num = nhospital
})
if (num > nhospital) {
result = NA
}
o = order(df[, 3], df[, 1])
result = df[o, ][num, 1]
c(result, state)
}
output = do.call(rbind, lapply(states, rank_in_state))
output = output[order(output[, 2]), ]
rownames(output) = output[, 2]
colnames(output) = c("hospital", "state")
data.frame(output)
}
head(rankall("heart attack", 20), 10)
tail(rankall("pneumonia", "worst"), 3)
tail(rankall("heart failure"), 10)
submit()
setwd("~/Documents/Coursera/Data Science/R programming")
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
R.version.string
install.packages("swirl")
library(swirl)
swirl()
5 + 7
bye()
swirl()
5+7
5 + 7
x >- 5+7
x <- 5+7
x
y <- x -3
y
z <- c(1.1,9,3.14)
?c
z
c(z, 555)
c(z, 555,z)
z*2+100
my_sqrt <- sqrt(z-1)
my_sqrt
my_div<-z/my_sqrt
my_div
c(1,2,3,4)+c(0,10)
c(1, 2, 3, 4) + c(0, 10, 100)
c(1, 2, 3, 4) + c(0, 10, 100)
z*2+1000
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
file.dest <- 'ACS.csv'
# download from the URL
download.file(file.url, file.dest, method='curl' )
# read the data
ACS <- read.csv('ACS.csv')
# tabulate the value variable (VAL)
table(ACS$VAL)
# extract the value of code 24 (1,000,000+)
table(ACS$VAL)[[24]]
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
file.dest <- 'ACS2.csv'
# download from the URL
download.file(file.url, file.dest, method='curl' )
# load the data.table package
library(data.table)
# read the data
DT <- fread('ACS2.csv')
# time the processes
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
file.dest <- 'ACS2.csv'
# download from the URL
download.file(file.url, file.dest, method='curl' )
# load the data.table package
library(data.table)
# read the data
DT <- fread('ACS2.csv')
# time the processes
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
install.packages(c("codetools", "RCurl", "swirl"))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
install.packages(c("boot", "class", "cluster", "digest", "foreign", "httr", "KernSmooth", "lattice", "manipulate", "MASS", "Matrix", "mgcv", "nlme", "nnet", "rpart", "spatial", "stringr", "survival", "testthat"))
# time the processes
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
file.dest <- 'ACS2.csv'
# download from the URL
download.file(file.url, file.dest, method='curl' )
# load the data.table package
library(data.table)
# read the data
DT <- fread('ACS2.csv')
# time the processes
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
install.packages("data.table")
# write the file url and file destination to an object
file.url <- 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06pid.csv'
file.dest <- 'ACS2.csv'
# download from the URL
download.file(file.url, file.dest, method='curl' )
# load the data.table package
library(data.table)
# read the data
DT <- fread('ACS2.csv')
# time the processes
system.time(mean(DT$pwgtp15,by=DT$SEX))
system.time(tapply(DT$pwgtp15,DT$SEX,mean))
system.time(sapply(split(DT$pwgtp15,DT$SEX),mean))
system.time(mean(DT[DT$SEX==1,]$pwgtp15); mean(DT[DT$SEX==2,]$pwgtp15))
system.time(DT[,mean(pwgtp15),by=SEX])
system.time(rowMeans(DT)[DT$SEX==1]; rowMeans(DT)[DT$SEX==2])
library(httr)
direccion <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
archivo <- "ss06hid.csv"
download.file(direccion, archivo, method="curl")
data <- read.csv("ss06hid.csv")
logicalvector <- data$ACR==3 & data$AGS==6
first3 <- which(logicalvector)[1:3] # which() treats NAs as FALSE
first3
library(jpeg)
direccion2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
archivo2 <- "jeff.jpg"
download.file(direccion2, archivo2, method="curl")
foto <- readJPEG("jeff.jpg", native = TRUE)
quantile(foto)
install.packages("jpeg")
library(jpeg)
direccion2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
archivo2 <- "jeff.jpg"
download.file(direccion2, archivo2, method="curl")
foto <- readJPEG("jeff.jpg", native = TRUE)
quantile(foto)
library(data.table)
direccion3 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
archivo3 <- "GDP.csv"
download.file(direccion3, archivo3, method="curl")
GDP <- data.table(read.csv("GDP.csv", skip = 4, nrows = 191))
GDP <- GDP[X != ""]
GDP <- GDP[, list(X, X.1, X.3, X.4)]
setnames(GDP, c("X", "X.1", "X.3", "X.4"), c("CountryCode", "rankingGDP", "Long.Name", "GDP"))
direccion4 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
archivo4 <- "EDSTATS_Country.csv"
download.file(direccion4, archivo4, method="curl")
EDSTATS <- data.table(read.csv("EDSTATS_Country.csv"))
data2 <- merge(GDP, EDSTATS, all = TRUE, by = c("CountryCode"))
sum(!is.na(unique(data2$rankingGDP)))
data2[order(rankingGDP, decreasing = TRUE), list(CountryCode, Long.Name.x, Long.Name.y, rankingGDP, GDP)][13]
data2[, mean(rankingGDP, na.rm = TRUE), by = Income.Group]
breaks <- quantile(data2$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
data2$quantileGDP <- cut(data2$rankingGDP, breaks = breaks)
data2[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
quentile <- c(0.2,0.4,0.6,0.8,1)
q <- quantile(combined$V2, quentile)
q1 <- combined$V2 <= 38
xtabs(q1 ~ combined$Income.Group)
breaks <- quantile(data2$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
data2$quantileGDP <- cut(data2$rankingGDP, breaks = breaks)
data2[Income.Group == "Lower middle income   ", .N, by = c("Income.Group", "quantileGDP")]
breaks <- quantile(data2$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
data2$quantileGDP <- cut(data2$rankingGDP, breaks = breaks)
data2[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/housingIdaho.csv", method = "curl")
housingIdaho <- read.csv("./data/housingIdaho.csv")
agricultureLogical <- housingIdaho$ACR == 3 & housingIdaho$AGS == 6
which(agricultureLogical)
finalTable$RankGroup = cut2(finalTable$Rank,g=5)
table(finalTable$RankGroup)
table(finalTable$RankGroup, finalTable$Income.Group)
install.packages("Hmisc")
library(Hmisc)
finalTable$RankGroup = cut2(finalTable$Rank,g=5)
table(finalTable$RankGroup)
table(finalTable$RankGroup, finalTable$Income.Group)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv"
download.file(fileUrl, destfile = "./data/housingIdaho.csv", method = "curl")
housingIdaho <- read.csv("./data/housingIdaho.csv")
agricultureLogical <- housingIdaho$ACR == 3 & housingIdaho$AGS == 6
which(agricultureLogical)
breaks <- quantile(data2$rankingGDP, probs = seq(0, 1, 0.2), na.rm = TRUE)
data2$quantileGDP <- cut(data2$rankingGDP, breaks = breaks)
data2[Income.Group == "Lower middle income", .N, by = c("Income.Group", "quantileGDP")]
write.table(tidy, "tidy.txt", sep="\t")
## Create one R script called run_analysis.R that does the following:
## 1. Merges the training and the test sets to create one data set.
## 2. Extracts only the measurements on the mean and standard deviation for each measurement.
## 3. Uses descriptive activity names to name the activities in the data set
## 4. Appropriately labels the data set with descriptive activity names.
## 5. From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
setwd("~/Data Science/Cleaning Data/Course Project/")
## tr for trainig
## te for test
tr[,563] =  read.csv("UCI HAR Dataset/train/subject_train.txt", sep="", header=FALSE)
tr =        read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
tr[,562] =  read.csv("UCI HAR Dataset/train/Y_train.txt", sep="", header=FALSE)
te[,563] =  read.csv("UCI HAR Dataset/test/subject_test.txt", sep="", header=FALSE)
te =        read.csv("UCI HAR Dataset/test/X_test.txt", sep="", header=FALSE)
te[,562] =  read.csv("UCI HAR Dataset/test/Y_test.txt", sep="", header=FALSE)
activityLabels = read.csv("UCI HAR Dataset/activity_labels.txt", sep="", header=FALSE)
# Read features and make the feature names better suited for R with some substitutions
features = read.csv("UCI HAR Dataset/features.txt", sep="", header=FALSE)
features[,2] = gsub('-mean', 'Mean', features[,2])
features[,2] = gsub('-std', 'Std', features[,2])
features[,2] = gsub('[-()]', '', features[,2])
# Merge training and test sets together
allData = rbind(tr, te)
# Get only the data on mean and std. dev.
colsWeWant <- grep(".*Mean.*|.*Std.*", features[,2])
# First reduce the features table to what we want
features <- features[colsWeWant,]
# Now add the last two columns (subject and activity)
colsWeWant <- c(colsWeWant, 562, 563)
# And remove the unwanted columns from allData
allData <- allData[,colsWeWant]
# Add the column names (features) to allData
colnames(allData) <- c(features$V2, "Activity", "Subject")
colnames(allData) <- tolower(colnames(allData))
currentActivity = 1
for (currentActivityLabel in activityLabels$V2) {
allData$activity <- gsub(currentActivity, currentActivityLabel, allData$activity)
currentActivity <- currentActivity + 1
}
allData$activity <- as.factor(allData$activity)
allData$subject <- as.factor(allData$subject)
tidy = aggregate(allData, by=list(activity = allData$activity, subject=allData$subject), mean)
# Remove the subject and activity column, since a mean of those has no use
tidy[,90] = NULL
tidy[,89] = NULL
write.table(tidy, "tidy.txt", sep="\t")
setwd("~/Documents/Coursera/Data Science/Cleaning Data/Course Project/")
## tr for trainig
## te for test
tr[,563] =  read.csv("UCI HAR Dataset/train/subject_train.txt", sep="", header=FALSE)
tr =        read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
tr[,562] =  read.csv("UCI HAR Dataset/train/Y_train.txt", sep="", header=FALSE)
te[,563] =  read.csv("UCI HAR Dataset/test/subject_test.txt", sep="", header=FALSE)
te =        read.csv("UCI HAR Dataset/test/X_test.txt", sep="", header=FALSE)
te[,562] =  read.csv("UCI HAR Dataset/test/Y_test.txt", sep="", header=FALSE)
activityLabels = read.csv("UCI HAR Dataset/activity_labels.txt", sep="", header=FALSE)
# Read features and make the feature names better suited for R with some substitutions
features = read.csv("UCI HAR Dataset/features.txt", sep="", header=FALSE)
features[,2] = gsub('-mean', 'Mean', features[,2])
features[,2] = gsub('-std', 'Std', features[,2])
features[,2] = gsub('[-()]', '', features[,2])
# Merge training and test sets together
allData = rbind(tr, te)
# Get only the data on mean and std. dev.
colsWeWant <- grep(".*Mean.*|.*Std.*", features[,2])
# First reduce the features table to what we want
features <- features[colsWeWant,]
# Now add the last two columns (subject and activity)
colsWeWant <- c(colsWeWant, 562, 563)
# And remove the unwanted columns from allData
allData <- allData[,colsWeWant]
# Add the column names (features) to allData
colnames(allData) <- c(features$V2, "Activity", "Subject")
colnames(allData) <- tolower(colnames(allData))
currentActivity = 1
for (currentActivityLabel in activityLabels$V2) {
allData$activity <- gsub(currentActivity, currentActivityLabel, allData$activity)
currentActivity <- currentActivity + 1
}
allData$activity <- as.factor(allData$activity)
allData$subject <- as.factor(allData$subject)
tidy = aggregate(allData, by=list(activity = allData$activity, subject=allData$subject), mean)
# Remove the subject and activity column, since a mean of those has no use
tidy[,90] = NULL
tidy[,89] = NULL
write.table(tidy, "tidy.txt", sep="\t")
setwd("~/Documents/Coursera/Data Science/Cleaning Data/Course Project/")
## tr for trainig
## te for test
training[,563] =  read.csv("UCI HAR Dataset/train/subject_train.txt", sep="", header=FALSE)
training =        read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
setwd("~/Documents/Coursera/Data Science/Cleaning Data/Course Project/")
## tr for trainig
## te for test
training =        read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
training[,562] =  read.csv("UCI HAR Dataset/train/Y_train.txt", sep="", header=FALSE)
training[,563] =  read.csv("UCI HAR Dataset/train/subject_train.txt", sep="", header=FALSE)
test =        read.csv("UCI HAR Dataset/test/X_test.txt", sep="", header=FALSE)
test[,562] =  read.csv("UCI HAR Dataset/test/Y_test.txt", sep="", header=FALSE)
test[,563] =  read.csv("UCI HAR Dataset/test/subject_test.txt", sep="", header=FALSE)
activityLabels = read.csv("UCI HAR Dataset/activity_labels.txt", sep="", header=FALSE)
# Read features and make the feature names better suited for R with some substitutions
features = read.csv("UCI HAR Dataset/features.txt", sep="", header=FALSE)
features[,2] = gsub('-mean', 'Mean', features[,2])
features[,2] = gsub('-std', 'Std', features[,2])
features[,2] = gsub('[-()]', '', features[,2])
# Merge training and test sets together
allData = rbind(tr, te)
# Get only the data on mean and std. dev.
colsWeWant <- grep(".*Mean.*|.*Std.*", features[,2])
# First reduce the features table to what we want
features <- features[colsWeWant,]
# Now add the last two columns (subject and activity)
colsWeWant <- c(colsWeWant, 562, 563)
# And remove the unwanted columns from allData
allData <- allData[,colsWeWant]
# Add the column names (features) to allData
colnames(allData) <- c(features$V2, "Activity", "Subject")
colnames(allData) <- tolower(colnames(allData))
currentActivity = 1
for (currentActivityLabel in activityLabels$V2) {
allData$activity <- gsub(currentActivity, currentActivityLabel, allData$activity)
currentActivity <- currentActivity + 1
}
allData$activity <- as.factor(allData$activity)
allData$subject <- as.factor(allData$subject)
tidy = aggregate(allData, by=list(activity = allData$activity, subject=allData$subject), mean)
# Remove the subject and activity column, since a mean of those has no use
tidy[,90] = NULL
tidy[,89] = NULL
write.table(tidy, "tidy.txt", sep="\t")
setwd("~/Documents/Coursera/Data Science/Cleaning Data/Course Project/")
## read each file for trainig and test
training =        read.csv("UCI HAR Dataset/train/X_train.txt", sep="", header=FALSE)
training[,562] =  read.csv("UCI HAR Dataset/train/Y_train.txt", sep="", header=FALSE)
training[,563] =  read.csv("UCI HAR Dataset/train/subject_train.txt", sep="", header=FALSE)
test =        read.csv("UCI HAR Dataset/test/X_test.txt", sep="", header=FALSE)
test[,562] =  read.csv("UCI HAR Dataset/test/Y_test.txt", sep="", header=FALSE)
test[,563] =  read.csv("UCI HAR Dataset/test/subject_test.txt", sep="", header=FALSE)
# read activy labels
activityLabels = read.csv("UCI HAR Dataset/activity_labels.txt", sep="", header=FALSE)
# Read features
features = read.csv("UCI HAR Dataset/features.txt", sep="", header=FALSE)
features[,2] = gsub('-mean', 'Mean', features[,2])
features[,2] = gsub('-std', 'Std', features[,2])
features[,2] = gsub('[-()]', '', features[,2])
# Use of rbind to merge training and test
allData = rbind(tr, te)
# Get only the data on mean and std. dev.
#colsWeWant <- grep(".*Mean.*|.*Std.*", features[,2])
outputcols <- grep(".*Mean.*|.*Std.*", features[,2])
# First reduce the features table to what we want
features <- features[outputcols,]
# Now add the last two columns (subject and activity)
outputcols <- c(outputcols, 562, 563)
# And remove the unwanted columns from allData
allData <- allData[,outputcols]
# Add the column names (features) to allData
colnames(allData) <- c(features$V2, "Activity", "Subject")
colnames(allData) <- tolower(colnames(allData))
currentActivity = 1
for (currentActivityLabel in activityLabels$V2) {
allData$activity <- gsub(currentActivity, currentActivityLabel, allData$activity)
currentActivity <- currentActivity + 1
}
allData$activity <- as.factor(allData$activity)
allData$subject <- as.factor(allData$subject)
tidy = aggregate(allData, by=list(activity = allData$activity, subject=allData$subject), mean)
# Remove the subject and activity column, since a mean of those has no use
tidy[,90] = NULL
tidy[,89] = NULL
write.table(tidy, "tidy.txt", sep="\t")
if (!require("data.table")) {
install.packages("data.table")
}
if (!require("reshape2")) {
install.packages("reshape2")
}
require("data.table")
require("reshape2")
# Load: activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
# Load: data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
# Bind data
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels   = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data      = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data   = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = "./tidy_data.txt")
# Load: activity labels
activity_labels <- read.table("./UCI HAR Dataset/activity_labels.txt")[,2]
# Load: data column names
features <- read.table("./UCI HAR Dataset/features.txt")[,2]
# Extract only the measurements on the mean and standard deviation for each measurement.
extract_features <- grepl("mean|std", features)
# Load and process X_test & y_test data.
X_test <- read.table("./UCI HAR Dataset/test/X_test.txt")
y_test <- read.table("./UCI HAR Dataset/test/y_test.txt")
subject_test <- read.table("./UCI HAR Dataset/test/subject_test.txt")
names(X_test) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_test = X_test[,extract_features]
# Load activity labels
y_test[,2] = activity_labels[y_test[,1]]
names(y_test) = c("Activity_ID", "Activity_Label")
names(subject_test) = "subject"
# Bind data
test_data <- cbind(as.data.table(subject_test), y_test, X_test)
# Load and process X_train & y_train data.
X_train <- read.table("./UCI HAR Dataset/train/X_train.txt")
y_train <- read.table("./UCI HAR Dataset/train/y_train.txt")
subject_train <- read.table("./UCI HAR Dataset/train/subject_train.txt")
names(X_train) = features
# Extract only the measurements on the mean and standard deviation for each measurement.
X_train = X_train[,extract_features]
# Load activity data
y_train[,2] = activity_labels[y_train[,1]]
names(y_train) = c("Activity_ID", "Activity_Label")
names(subject_train) = "subject"
# Bind data
train_data <- cbind(as.data.table(subject_train), y_train, X_train)
# Merge test and train data
data = rbind(test_data, train_data)
id_labels   = c("subject", "Activity_ID", "Activity_Label")
data_labels = setdiff(colnames(data), id_labels)
melt_data      = melt(data, id = id_labels, measure.vars = data_labels)
# Apply mean function to dataset using dcast function
tidy_data   = dcast(melt_data, subject + Activity_Label ~ variable, mean)
write.table(tidy_data, file = "./tidy_data.txt")
install.packages("knitr")
